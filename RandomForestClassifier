'''
--------------------------------------------------------------------------------------------------
        RANDOM FOREST CLASSIFIER
--------------------------------------------------------------------------------------------------
'''

# Import Lib's
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Importando dataset
dataset = pd.read_csv('train_titanic.csv', sep=',')
#https://www.kaggle.com/c/titanic/data


'''
--------------------------------------------------------------------------------------------------
        EXPLORING YOUR DATASET
--------------------------------------------------------------------------------------------------
'''

dataset.head()
dataset.info()
dataset.describe()

# Features most importants
corr_matrix	=	dataset.corr()
corr_matrix["Survived"].sort_values(ascending=False)
# Correlation 
from pandas.tools.plotting import scatter_matrix
attributes = ["Survived","Fare","Pclass","Age"]
scatter_matrix(dataset[attributes],	figsize=(12,	8))

# PLOT 2D
dataset.plot(kind="scatter", x="OverallQual", y="SalePrice", alpha=0.5)
# PLOT 4D - Size (s) it's not necessary
dataset.plot(kind="scatter", x="OverallQual", y="GrLivArea", alpha=0.5, s=dataset["GarageCars"]*100, c=dataset["SalePrice"], label="SalePrice" ,cmap=plt.get_cmap("jet"), colorbar=True,)
plt.legend()

# BOXPLOT
import seaborn as sns
sns.boxplot(x="Pclass", y="Age", hue="Survived",data=dataset, palette="Set3")

''' 
--------------------------------------------------------------------------------------------------
        DATA PREP 
--------------------------------------------------------------------------------------------------
'''
# SELECTING X and y
X = dataset[["Age","Sex"]]
y = dataset.iloc[:,1]
# X = dataset.iloc[:,[1,3]].values

# HANDLING MISSING DATA
# fillnan with mean/median/most_frequent
from sklearn.preprocessing import Imputer
imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)
imputer = imputer.fit(X.iloc[:,0].values.reshape((len(X),1)))
X.iloc[:,0] = imputer.transform(X.iloc[:,0].values.reshape((len(X),1)))
X.info()
X.drop(0, axis=1, inplace=True)
# Drop Nan
X.dropna(inplace = True)
y.dropa(inplace = True)

# ENCODING CATEGORICAL FEATURES
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
# The values 0,1,2,etc into categorical values
labelencoder_X = LabelEncoder()
X.iloc[:,1] = labelencoder_X.fit_transform(X.iloc[:, 1])
# Here we create the dummies
onehotencoder = OneHotEncoder(categorical_features=[1])
X = onehotencoder.fit_transform(X).toarray()
#Delete a COlumn in a array
X = np.delete(X, 0, axis=1)
# The same to y
labelencoder_y = LabelEncoder()
y = labelencoder_y.fit_transform(y)

# FEATURE SCALING
# Saving the original values 
Xo = X
yo = y
    # Standardisation
    #X = ((X-X.mean())/X.std())
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_std = sc_X.fit_transform(X[:,1].reshape((len(X),1)))
X = np.c_[X,X_std]
X = X[:,[0,2,3]]
    # y Standardisation
sc_y = StandardScaler()
y = sc_y.fit_transform(y.reshape((len(y),1)))

'''
    # Mean normalization
X = ((X-X.mean())/(X.max()-X.min()))
        # Inverse Transform 
X = (Xo.max()-Xo.min())*X+Xo.mean()
    # Min-Max scaling
X = ((X-X.min())/(X.max()-X.min()))
        # Inverse Tranform
X = (Xo.max()-Xo.min())*X+Xo.min()
'''

''' 
--------------------------------------------------------------------------------------------------
        SPLIT THE DATA SET INTO TRAINING AND TEST SET
--------------------------------------------------------------------------------------------------
'''
# HOLD OUT
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    # (Ordered)
'''
Pos=8
X_train, y_train  = X[:Pos,:] , y[:Pos]
X_test, y_test = X[Pos:,:], y[Pos:]
#OBS.: iloc para df e sr[:,:] para series
'''


''' 
--------------------------------------------------------------------------------------------------
        TRAINING THE MODEL
--------------------------------------------------------------------------------------------------
'''
# if is a array like (n,) you have to reshape it with .reshape(n,1)
# sometimes you have to put df.values.reshape
X_train = X_train.reshape(np.size(X_train,0),np.size(X_train,1))
X_test = X_test.reshape(np.size(X_test,0),np.size(X_test,1))
y_train = y_train.reshape(len(y_train), 1)
y_test = y_test.reshape(len(y_test),1)

# Fit your method to your training set
from sklearn.ensemble import  RandomForestClassifier
classifier = RandomForestClassifier(n_estimators=10,
                                    max_depth=5,
                                    oob_score=False)
classifier.fit(X_train, y_train)

'''
--------------------------------------------------------------------------------------------------
        PREDICT 
--------------------------------------------------------------------------------------------------
'''
# y_pred
y_pred = classifier.predict(X_test)
y_pred_proba = classifier.predict_proba(X_test)

# Predict a specific Xi value
X_new = np.array([9,1500]).reshape((1,2))
y_new = sc_y.inverse_transform(regressor.predict( sc_X.transform(X_new) ))
print(y_new)

'''
--------------------------------------------------------------------------------------------------
        EVALUATING MODEL
--------------------------------------------------------------------------------------------------
'''
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.metrics import roc_auc_score, confusion_matrix

print("Precision: ", precision_score(y_test, y_pred))
print("Recall: ",recall_score(y_test, y_pred))
print("Accuracy: ",accuracy_score(y_test, y_pred))
print("F1: ",f1_score(y_test, y_pred))
print("Roc auc: ", roc_auc_score(y_test,y_pred))

conf_mtx = confusion_matrix(y_test, y_pred)

classifier.feature_importances_
classifier.oob_score_

'''
--------------------------------------------------------------------------------------------------
        CROSS VALIDATION
--------------------------------------------------------------------------------------------------
'''
# K-FOLD or LOOCV

# K-Folds:
k=10
# LOOCV
k = len(X_train)

from sklearn.model_selection import cross_val_score
metrics_lt = ['precision', 'recall', 'accuracy','f1','roc_auc']
for m in metrics_lt:
    metrics_cl = cross_val_score(estimator=classifier, X=X_train, y=y_train, 
                                 cv=k, scoring =m)
    print(m,' mean: ', metrics_cl.mean())
    print(m,' std: ', metrics_cl.std())


''' 
--------------------------------------------------------------------------------------------------
        VISUALISING THE RESULTS
--------------------------------------------------------------------------------------------------
'''
# X scaled into X originalm or you can use Xo
X_plot_train = np.   sc_X.inverse_transform(X_train[:,-1])
X_plot_test = sc_X.inverse_transform(X_test)


X_train[:,[0,1]]
from matplotlib.colors import ListedColormap
X_set, y_set = X_train ,  y_train
X1, X2 = np.meshgrid(np.arange(start=X_set[:, 0].min() - .5, stop=X_set[:, 0].max() + .5, step=0.1),
                     np.arange(start=X_set[:, 1].min() - .5, stop=X_set[:, 1].max() + .5, step=0.1))
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha=0.75, cmap=ListedColormap(('red', 'blue')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c=ListedColormap(('red', 'blue'))(i),  alpha=0.5,label=j)
plt.title('K-NN')
plt.xlabel('Sex')
plt.ylabel('Age')
plt.legend()
plt.show()

# Visualizing the Test set results
from matplotlib.colors import ListedColormap
X_set, y_set = X_test, y_test
X1, X2 = np.meshgrid(np.arange(start=X_set[:, 0].min() - 1, stop=X_set[:, 0].max() + 1, step=0.1),
                     np.arange(start=X_set[:, 1].min() - 1, stop=X_set[:, 1].max() + 1, step=0.1))

plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha=0.75, cmap=ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c=ListedColormap(('red', 'green'))(i), label=j)
plt.title('K-NN (Test set)')
plt.xlabel('Sex')
plt.ylabel('Age')
plt.legend()
plt.show()
